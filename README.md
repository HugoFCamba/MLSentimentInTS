# Práctica Final Aprendizaje Automático
## **Modelización y predicción de series temporales financieras mediante análisis de sentimientos y Machine Learning.**

Trabajo Realizado Por: Hugo Fernández Camba, Diego Moreno Cortés-Cavanillas, Alberto Cañuelo Gómez.

A lo largo de la asignatura Aprendizaje Automático del Doble Grado en Economía - Matemáticas y Estadística, hemos estudiado múltiples modelos para extraer la máxima cantidad de información de un conjunto de datos, con la finalidad de construir herramientas que nos permitan predecir la pertenencia a una clase o el valor de una cierta variable, para una observación inédita. Nuestro primer objetivo, por tanto, es demostrar funcionamiento y utilidad práctica de algunas de las principales familias de modelos.
Además, también deseábamos afianzar el sustancial conocimiento adquirido en lo relativo a métodos y usos en programación. Con esta finalidad, exploramos prácticamente todos los recursos y librerías con los que nos hemos familiarizados a lo largo del curso, así como algunas de las estructuras más notorias, como son los Pipelines.
Sin embargo, nuestra intención con este trabajo no es solamente reforzar y demostrar lo aprendido durante el curso y en las clases, sino emplear dicha experiencia como palanca para adentrarnos en temáticas más complejas en el ámbito de Machine Learning. En primer lugar, deseábamos explorar el estudio de esta disciplina a datos en Series Temporales, que constituyen un volumen masivo de información de enorme riqueza en la economía moderna. En particular, por nuestra formación complementaria como economistas, hemos centrado nuestras atenciones en datos de índole financiera, como son el precio de múltiples activos financieros.
En la mayoría de casos de estudio práctico a lo largo del curso han predominado fuentes de datos puramente cuantitativos, si bien en las clases teóricas sí se ha estudiado la aplicación de Machine Learning, y en particular de Deep Learning, a datos textuales y gráficos. Con el presente trabajo hemos intentado adentrarnos también en los primeros, a través del análisis de sentimientos en titulares de noticias o textos cortos (tweets). El análisis realizado se limita a textos directamente relacionados con los activos financieros que son objeto de nuestro estudio, y emplea métodos estructurados para extraer una medida del 'sentimiento' en torno a los mismos. Dejamos para futuros proyectos el desarrollo de métodos de análisis directo de texto, con herramientas más exhaustivas y customizables, como algoritmos de vectorización, y un sujeto de estudio más amplio, como puedan ser textos, y no solamente titulares, de noticias de múltiples medios y que no se refieran directamente al activo, pero que puedan guardar cualquier relación con el mismo.
![image](https://github.com/HugoFCamba/MLSentimentInTS/assets/98669052/b9cb5356-a80d-48bc-b6f1-48f2c12f4d5a)

### Metodología
Siguiendo la estructura del índice anterior, nuestra metodología para el presenta trabajo ha consistidos en lo siguiente. En primer lugar, hemos estudiado con detalle el problema del análisis de sentimientos y las herramientas disponibles para ello en Python. También hemos buscado información relativa al tratamiento de datos de series temporales, a aplicaciones de Machine Learning en finanzas, y naturalmente a la intersección de ambos campos.

Tras reunir el conocimiento suficiente en cuanto a las herramientas necesarias y óptimas para nuestro problema, nuestra atención se posó sobre la obtención de las bases de datos y de la información necesaria para realizar un análisis básico sobre los mismos que nos sirva para nuestro análisis. Para ello, realizamos un trabajo exhaustivo sobre diversas técnicas de scrapping, con múltiples sujetos de las mismas. Pese a las múltiples complicaciones que se detallan en su momento, en este script se presenta un par de estas técnicas implementadas. Sin embargo, la dimensión y tipología de estos algoritmos no es sufiente a nuestros ojos para llevar a cabo un trabajo de previsión con garantías, por lo que proseguimos a formar una base de datos adecuada mediante la fusión de información financiera y de texto obtenidas por terceros.

Con estos pasos preliminares, empleamos una metodología eminentemente práctica en la implantación del análisis exploratorio y de los modelos fundamentales, muchos de ellos tratados en clase, para clasificación y regresión. Desarrollamos el código originalmente, apoyándonos en los conocimientos de teoría del Aprendizaje Automático, y de prácticas de programación para el mismo. Se resuelven las dudas mediante herramientas de IA y sobre todo haciendo uso de posts en StackOverflow. Realizamos un análisis cualitativo de nuestros resultados, basado en nuestra experiencia previa en este tipo de proyectos, evaluando su validez y utilidad mediante las métricas y algoritmos habituales.

### Datasets
La información que vamos a emplear se obtiene en nuestro caso de dos fuentes distintas, en función del tipo de datos. En el caso de los datos financieros, empleamos la librería Yahoo Finance (yfinance) a partir de la cual construímos diversas métricas financieras de utilidad para la predicción de la evolución futura de la acción.

Para las variables textuales, sin embargo, hemos estudiado un número mucho mayor de posibilidades, fundamentalmente en lo relativo a la obtención mediante scrapping de titulares o tweets. A lo largo de dicho proceso se han dado numerosos problemas debidos fundamentalmente a la deprecación de funciones, a cambios en la estructura de ciertas webs que complican su navegación, a la necesidad de nociones más avanzadas de programación en lenguages web y sobre todo debido a un déficit en nuestras capacidades de poder de computación con las herramientas disponibles. Por ese motivo, y pese a que demostramos algunos de los métodos que nos han resultado menos problemáticos, tomamos la decisión de emplear para el core de nuestro análisis una base de datos de texto de terceros, que nos proporcionase un volumen mayor de información tanto cronológica como entrópicamente. Nos hemos inclinado por la base disponible en:

https://www.kaggle.com/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020

Nuestra intención original consistía en emplear herramientas de scrapping para obtener una base similar por nuestros propios medios, incorporando también noticias del sector y de la economía general, de modo que pudieramos, en instantes futuros, realizar un análisis con vectorización de textos. Sin embargo, la reciente decisión de Elon Musk de privar de acceso a Twitter a las múltiples APIs externas que servían a este fin nos ha forzado a tomar las decisiones previamente señaladas.
